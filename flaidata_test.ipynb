{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c719b3-79e7-4b4f-92bb-cf6901c97565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021c42a5-b40e-4582-a02e-4936bcb2b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openapi_pydantic import parse_obj, OpenAPI, PathItem, Response\n",
    "from rich import print\n",
    "\n",
    "# open_api = parse_obj(data)\n",
    "# print(open_api.paths['/api/datapoint/videos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "489bba43-d742-4061-96e0-cc22eba14ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"https://flaidata.tiktok-alltrends.com:442/swagger/v2/datapoint-api.json\") as url:\n",
    "    spec_json = json.load(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1b5574-44a9-43d9-9fa4-a199715862fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79e2aa-833f-4fa2-95cf-4598916e873b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db891ae8-9680-48c7-82ee-c745e4ab275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_spec(spec_json, allow_endpoints= ['/api/datapoint/author', '/api/datapoint/authors', '/api/datapoint/sounds']):\n",
    "    output_spec = spec_json.copy()\n",
    "    temp_paths = {}\n",
    "    for route, operations in output_spec[\"paths\"].items():\n",
    "        if route in allow_endpoints:\n",
    "            temp_paths[route] = operations\n",
    "    output_spec[\"paths\"] = temp_paths\n",
    "    \n",
    "    return output_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f810fc5c-ac50-400b-a02a-4846a400fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_spec = cut_spec(spec_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49f6aad5-d019-4ee7-9e60-24e16f4f5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc238f-e52a-4b34-83f4-375b92c68975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00425703-43f0-4379-82dd-a86c1a6ecb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a65c2f-287a-499f-9d96-38e0ed2e007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e37bc5-08fb-401b-9d6e-f0efc5d1c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ed84c0-885c-4f01-a689-0662a45ec5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be9bcb5-a120-440c-a53a-f87972e85e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints = [\n",
    "    (route, operation)\n",
    "    for route, operations in c_spec[\"paths\"].items()\n",
    "    for operation in operations\n",
    "    if operation in [\"get\", \"post\"]\n",
    "]\n",
    "len(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41bcd749-69cd-4da3-a846-5b00c9763861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36033\n",
      "15564\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import yaml\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "\n",
    "\n",
    "print(count_tokens(yaml.dump(spec_json))) \n",
    "print(count_tokens(yaml.dump(c_spec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ed7a81-1cfa-49de-8516-1ea9159bf1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/api/datapoint/sounds', 'get'),\n",
       " ('/api/datapoint/authors', 'get'),\n",
       " ('/api/datapoint/author', 'get')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e854137-720c-4261-b443-ba19102d2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_3 = reduce_openapi_spec(c_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0318a403-eafe-4278-8e12-3205a64ec4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(spec_3_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "94dadc66-846f-4456-adff-48e3bb716c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "#os.environ[\"FLAIDATA_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c39d374-c830-477b-81f9-ad1c7887f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! printenv | grep 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad3eb2-c78f-4c65-9f4c-43df0f45ca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77ef3c8-9034-458d-a4e1-93aa34d4ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.requests import RequestsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2323c4-9783-4cfd-af19-12a42c4fe357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_headers(token):\n",
    "    return {\"accept\": \"application/json\", \n",
    "            \"Token\": token}\n",
    "\n",
    "headers = construct_headers(os.environ[\"FLAIDATA_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f59a841-6f7b-48ad-a695-ca8ce9269eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_wrapper = RequestsWrapper(headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad644ee-32c8-4049-94fc-f323965546ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackHandler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpt-3.5-turbo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSecretStr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morganization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mopenai_proxy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstreaming\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtiktoken_model_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_headers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_query\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhttp_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "`OpenAI` Chat large language models API.\n",
       "\n",
       "To use, you should have the\n",
       "environment variable ``OPENAI_API_KEY`` set with your API key.\n",
       "\n",
       "Any parameters that are valid to be passed to the openai.create call can be passed\n",
       "in, even if not explicitly saved on this class.\n",
       "\n",
       "Example:\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_community.chat_models import ChatOpenAI\n",
       "        openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\n",
       "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     AzureChatOpenAI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "ChatOpenAI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba53f972-dd30-41ba-addd-0dad35df12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.openapi import planner\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "#llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e862ee6b-efb1-462b-9ad6-957fe2ac0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.openapi import planner\n",
    "#! cat /home/mnemonic/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_community/agent_toolkits/openapi/planner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "339641f1-25f8-4202-b2c1-3bf1467ae486",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_gpt4 = planner.create_openapi_agent(spec_3, requests_wrapper, llm, verbose=True, return_intermediate_steps=True )\n",
    "# user_query = (\n",
    "#     \"Give me info about my sounds\"\n",
    "# )\n",
    "# agent_gpt4.run(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c0ece6d-bb27-4dcf-a0b3-65ed542b8c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
      "Action Input: Find the right API calls to retrieve information for author with authorId = 6964487193222464517\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. GET /api/datapoint/author with authorId = 6964487193222464517 to retrieve information for the specific author\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors\n",
      "2. GET /api/datapoint/author with authorId = 6964487193222464517\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to first get the list of authors to find the authorId for the specific author I want to retrieve more information about.\n",
      "\n",
      "Action: requests_get\n",
      "Action Input: \n",
      "{\n",
      "  \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\",\n",
      "  \"params\": {},\n",
      "  \"output_instructions\": \"Extract authorId for the author I want to get more information about\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe authorId for the author you want to get more information about is \"6909185617990009861\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Now that I have the authorId, I can proceed to get more information about the specific author.\n",
      "\n",
      "Action: requests_get\n",
      "Action Input: \n",
      "{\n",
      "  \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author\",\n",
      "  \"params\": {\n",
      "    \"authorId\": \"6964487193222464517\"\n",
      "  },\n",
      "  \"output_instructions\": \"Extract relevant information about the author\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor ID: 4edefc8a-5af8-4218-9154-ebddc2d481c4\n",
      "Author Name: ðŸ¥·â€”â€”Cbâ€‚Abdelâ€”â€”ðŸ¥·\n",
      "Subscribers: 125800\n",
      "Clips: 1309\n",
      "Likes: 1300000\n",
      "Digg Count: 186300\n",
      "URL: https://www.tiktok.com/@6964487193222464517\n",
      "Signature: ðŸ‘‘Wiled AbÃ©che ðŸ‘‘\n",
      "Verified: false\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: \n",
      "Author ID: 4edefc8a-5af8-4218-9154-ebddc2d481c4\n",
      "Author Name: ðŸ¥·â€”â€”Cbâ€‚Abdelâ€”â€”ðŸ¥·\n",
      "Subscribers: 125800\n",
      "Clips: 1309\n",
      "Likes: 1300000\n",
      "Digg Count: 186300\n",
      "URL: https://www.tiktok.com/@6964487193222464517\n",
      "Signature: ðŸ‘‘Wiled AbÃ©che ðŸ‘‘\n",
      "Verified: false\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAuthor ID: 4edefc8a-5af8-4218-9154-ebddc2d481c4\n",
      "Author Name: ðŸ¥·â€”â€”Cbâ€‚Abdelâ€”â€”ðŸ¥·\n",
      "Subscribers: 125800\n",
      "Clips: 1309\n",
      "Likes: 1300000\n",
      "Digg Count: 186300\n",
      "URL: https://www.tiktok.com/@6964487193222464517\n",
      "Signature: ðŸ‘‘Wiled AbÃ©che ðŸ‘‘\n",
      "Verified: false\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully retrieved the information for the author with authorId = 6964487193222464517.\n",
      "Final Answer: \n",
      "Author Name: ðŸ¥·â€”â€”Cbâ€‚Abdelâ€”â€”ðŸ¥·\n",
      "Subscribers: 125800\n",
      "Clips: 1309\n",
      "Likes: 1300000\n",
      "Digg Count: 186300\n",
      "URL: https://www.tiktok.com/@6964487193222464517\n",
      "Signature: ðŸ‘‘Wiled AbÃ©che ðŸ‘‘\n",
      "Verified: false\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What is the info for author = [{'authorId': 6964487193222464517}]\",\n",
       " 'output': 'Author Name: ðŸ¥·â€”â€”Cb\\u2002Abdelâ€”â€”ðŸ¥·\\nSubscribers: 125800\\nClips: 1309\\nLikes: 1300000\\nDigg Count: 186300\\nURL: https://www.tiktok.com/@6964487193222464517\\nSignature: ðŸ‘‘Wiled AbÃ©che ðŸ‘‘\\nVerified: false'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_gpt4(\"What is the info for author = [{'authorId': 6964487193222464517}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90e57ba3-ee98-428a-b73f-084af3e542e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
      "Action Input: I need to find the right API calls to retrieve information about the user's sounds\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/sounds to retrieve information about the user's sounds.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: GET /api/datapoint/sounds\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/sounds\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract musicId, title, creator, url\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMusic ID: 7301793564323892014\n",
      "Title: original sound\n",
      "Creator: Hippytð–¦¹ri\n",
      "URL: https://sf16-ies-music-va.tiktokcdn.com/obj/ies-music-ttp-dup-us/7301793569562561323.mp3\n",
      "\n",
      "Music ID: 7341591698076338949\n",
      "Title: sonido original\n",
      "Creator: Angel â˜„ï¸\n",
      "URL: https://v16-webapp-prime.us.tiktok.com/video/tos/useast5/tos-useast5-ve-27dcd7c799-tx/ocpBBqHf7iUlFBCeILsoJkTDQEdUJvQirF4nMA/?a=1988&ch=0&cr=0&dr=0&er=0&lr=default&cd=0%7C0%7C0%7C0&br=250&bt=125&bti=ODszNWYuMDE6&ft=GcAInInz7ThXLeRmXq8Zmo&mime_type=audio_mpeg&qs=6&rc=NDc7ZmdpNjo7ODk0NTVkOUBpM21wcng5cms8cTMzNzU8M0AvLi4xLl8yNjIxYC9eLV8wYSNoaGRpMmRzMmVgLS1kMTZzcw%3D%3D&btag=e00090000&expire=1709425083&l=20240302181656EE0B99E7290BB016C879&ply_type=3&policy=3&signature=1bf078f2db5b1a3dbec0b74b9d147399&tk=0\n",
      "\n",
      "Music ID: 7341576470920497925\n",
      "Title: original sound - IG: Ririiii.26\n",
      "Creator: IG: Ririiii.26\n",
      "URL: https://v16-webapp-prime.tiktok.com/video/tos/useast2a/tos-useast2a-v-27dcd7/o0EAJigAKX2fn98NPyWOBdkiUsIKM0pJBUhlio/?a=1988&ch=0&cr=0&dr=0&er=0&lr=default&cd=0%7C0%7C0%7C0&br=250&bt=125&bti=ODszNWYuMDE6&ft=GNDpcInz7Thq3ERmXq8Zmo&mime_type=audio_mpeg&qs=6&rc=PDdpOzM1aDtmPDY1aDw3N0Bpajg5b3c5cnU7cTMzNzU8M0BhYTRjYi4tX14xYi9gMDEyYSNiZ20zMmRjNmVgLS1kMTZzcw%3D%3D&btag=e00088000&expire=1709400920&l=202403021634357958F3D7C0CADF7D6EFF&ply_type=3&policy=3&signature=c8b63daf040a4bd1618cbe72058f4b68&tk=0\n",
      "\n",
      "Music ID: 7341472314813647649\n",
      "Title: sonido original\n",
      "Creator: crismi\n",
      "URL: https://v16-webapp-prime.tiktok.com/video/tos/useast2a/tos-useast2a-v-2370-euttp/osjiJlXy4fKEUJ1FDCYGiqYfuyEQlFQDHCPBii/?a=1988&ch=0&cr=0&dr=0&er=0&lr=default&cd=0%7C0%7C0%7C0&br=250&bt=125&bti=ODszNWYuMDE6&ft=GNDpcInz7Th6sIRmXq8Zmo&mime_type=audio_mpeg&qs=6&rc=PGVpODY7ODo5ZDM1OGU2M0Bpams3a285cmU1cTMzZjU8M0AvNWAxMC0uNjQxYV5jNWJhYSM1L19gMmRrYGVgLS1kMWNzcw%3D%3D&btag=e00088000&expire=1709387224&l=202403021246471284F8D7261BBD6C2826&ply_type=3&policy=3&signature=1878a49db5f0a9f9c341288ca7c55761&tk=0\n",
      "\n",
      "Music ID: 7341507126017133354\n",
      "Title: original sound\n",
      "Creator: Zilverk in English\n",
      "URL: https://v16-webapp-prime.tiktok.com/video/tos/maliva/tos-maliva-ve-27dcd7c799-us/o8zXBCfBpI5gE4yKmRMpP81SiAdBkiLAiIusMw/?a=1988&ch=0&cr=0&dr=0&er=0&lr=default&cd=0%7C0%7C0%7C0&br=250&bt=125&bti=ODszNWYuMDE6&ft=GNDpcInz7ThRgORmXq8Zmo&mime_type=audio_mpeg&qs=6&rc=NjQ3ZmloaGRnZzw4N2U2OEBpam9lOHM5cnA3cTMzZzU8NEBfLS0tLy4uNV4xYzQuNi9hYSNoZWxnMmRjX2VgLS1kMS9zcw%3D%3D&btag=e00088000&expire=1709427283&l=202403022354079865EE2D762AF6DCD5EB&ply_type=3&policy=3&signature=0c08b269d345e1f42527748c1c1280c7&tk=0\n",
      "\n",
      "Music ID: 7341527287657745157\n",
      "Title: Ø§Ù„ØµÙˆØª Ø§Ù„Ø£ØµÙ„ÙŠ\n",
      "Creator: à¿Ø§Ø³Ù€ðŸ”Ù€Ù€Ù„Ø§Ù… Ø§Ù„Ù€Ø³Ù€ÙˆÙ‡ÌÌ·Ì¸Ù€Ù€Ø§Ø¬ÙŠ â™ˆ\n",
      "URL: https://v16-webapp-prime.us.tiktok.com/video/tos/useast5/tos-useast5-ve-27dcd7c799-tx/oIJA4FXJQIu3UWXBEllQsgDeFxfFCBDiHM7iVK/?a=1988&ch=0&cr=0&dr=0&er=0&lr=default&cd=0%7C0%7C0%7C0&br=250&bt=125&bti=ODszNWYuMDE6&ft=GcAInInz7ThwsIRmXq8Zmo&mime_type=audio_mpeg&qs=6&rc=N2g5Nzk6ZTk7N2k6ZjQ6PEBpamp2OHg5cmY4cTMzNzU8M0BjLWBiXzEzNi8xMl4vYGAzYSMvLXJrMmRjZGVgLS1kMTZzcw%3D%3D&btag=e00088000&expire=1709405230&l=20240302124648EF7351795CE5B81F2628&ply_type=3&policy=3&signature=e207d25c3516c0ec709fc33883ca7988&tk=0\n",
      "\n",
      "Music ID: 7341526340903619333\n",
      "Title: \n",
      "Creator: \n",
      "URL:\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I have successfully executed the API call and extracted the music IDs, titles, creators, and URLs for the sounds.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI have successfully executed the API call and extracted the music IDs, titles, creators, and URLs for the sounds.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the information the user asked for.\n",
      "Final Answer: Here is the information about your sounds: [list of music IDs, titles, creators, and URLs]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Give me info about my sounds',\n",
       " 'output': 'Here is the information about your sounds: [list of music IDs, titles, creators, and URLs]'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_gpt4(\"Give me info about my sounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eebc36a2-7977-43c9-971a-41f2195492e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
      "Action Input: I need to find the right API calls to retrieve information about authors using only GB VideosLocation\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors with a query param for GB VideosLocation to retrieve information about authors in that location.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors with a query param for GB VideosLocation\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\",\n",
      "    \"params\": {\n",
      "        \"locationData\": \"GB\"\n",
      "    },\n",
      "    \"output_instructions\": \"Extract authorId for GB location videos\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThere are no specific authorIds for GB location videos in the provided API response.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: The API response does not provide specific authorIds for GB location videos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe API response does not provide specific authorIds for GB location videos.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to modify my plan to include an additional API call to filter authors by location.\n",
      "Action: api_planner\n",
      "Action Input: I need to find the right API calls to filter authors by location and then retrieve information about them.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors to retrieve a list of all authors\n",
      "2. Filter the list of authors by location (assuming there is a query parameter for location)\n",
      "3. GET /api/datapoint/author/{id} for each author to retrieve detailed information about them\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors to retrieve a list of all authors\n",
      "2. Filter the list of authors by location\n",
      "3. GET /api/datapoint/author/{id} for each author\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract authorId for each author\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor IDs:\n",
      "- 7012578244126311429\n",
      "- 6640869246728929286\n",
      "- 7139769752192910363\n",
      "- 6964487193222464517\n",
      "- 7139601558447588357\n",
      "- 7323120896553272353\n",
      "- 6801341354128950278\n",
      "- 7064343731571196933\n",
      "- 7246020936363885595\n",
      "- 6926711543360291846\n",
      "- 6790802089145844742\n",
      "- 7051480716266685445\n",
      "- 6961923651055551493\n",
      "- 6633635882816552966\n",
      "- 6644178361227329541\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/7012578244126311429\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract author details\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor details are not provided in the API response.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I cannot retrieve the author details from the API response. I would need more information or a different approach to extract the required data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI cannot retrieve the author details from the API response. I would need more information or a different approach to extract the required data.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should ask the user for more specific details about the information they are looking for regarding authors in the GB VideosLocation.\n",
      "Action: Ask User for more information\n",
      "Action Input: Request more specific details about the information needed regarding authors in the GB VideosLocation\u001b[0m\n",
      "Observation: Ask User for more information is not a valid tool, try one of [api_planner, api_controller].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should revise my approach and try to extract the required information using the available API calls.\n",
      "Action: api_planner\n",
      "Action Input: I need to find the right API calls to retrieve detailed information about authors in the GB VideosLocation.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If no authors are found in the GB VideosLocation, inform the user that the information is not available.\n",
      "4. If authors are found in the GB VideosLocation, proceed to the next step.\n",
      "5. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation to retrieve detailed information about each author.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If authors are found in the GB VideosLocation, proceed to the next step.\n",
      "4. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract authorId and region for each author\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor 1:\n",
      "- Author ID: 7201193244977169413\n",
      "- Region: Not specified\n",
      "\n",
      "Author 2:\n",
      "- Author ID: 7007883902724260870\n",
      "- Region: Not specified\n",
      "\n",
      "Author 3:\n",
      "- Author ID: 7041610289514824706\n",
      "- Region: Not specified\n",
      "\n",
      "Author 4:\n",
      "- Author ID: 6813811780881384453\n",
      "- Region: Not specified\n",
      "\n",
      "Author 5:\n",
      "- Author ID: 7012578244126311429\n",
      "- Region: Not specified\n",
      "\n",
      "Author 6:\n",
      "- Author ID: 6640869246728929286\n",
      "- Region: Not specified\n",
      "\n",
      "Author 7:\n",
      "- Author ID: 7139769752192910363\n",
      "- Region: Not specified\n",
      "\n",
      "Author 8:\n",
      "- Author ID: 6964487193222464517\n",
      "- Region: Not specified\n",
      "\n",
      "Author 9:\n",
      "- Author ID: 7139601558447588357\n",
      "- Region: Not specified\n",
      "\n",
      "Author 10:\n",
      "- Author ID: 7323120896553272353\n",
      "- Region: Not specified\n",
      "\n",
      "Author 11:\n",
      "- Author ID: 6801341354128950278\n",
      "- Region: Not specified\n",
      "\n",
      "Author 12:\n",
      "- Author ID: 7064343731571196933\n",
      "- Region: Not specified\n",
      "\n",
      "Author 13:\n",
      "- Author ID: 7246020936363885595\n",
      "- Region: Not specified\n",
      "\n",
      "Author 14:\n",
      "- Author ID: 6926711543360291846\n",
      "- Region: Not specified\n",
      "\n",
      "Author 15:\n",
      "- Author ID: 6790802089145844742\n",
      "- Region: Not specified\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mSince the region for each author is not specified in the response, I cannot determine if any authors are located in the GB VideosLocation. I will need to retry the API call with additional parameters to filter authors by region.\n",
      "Final Answer: Missing information to proceed with the plan.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mMissing information to proceed with the plan.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should ask the user for the specific location details they are looking for regarding authors.\n",
      "Action: Ask User for more information\n",
      "Action Input: Request specific details about the location of authors the user is interested in\u001b[0m\n",
      "Observation: Ask User for more information is not a valid tool, try one of [api_planner, api_controller].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should revise my approach and try to extract the required information using the available API calls.\n",
      "Action: api_planner\n",
      "Action Input: I need to find the right API calls to retrieve detailed information about authors in the GB VideosLocation.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If no authors are found in the GB VideosLocation, inform the user that the information is not available\n",
      "4. If authors are found in the GB VideosLocation, proceed to the next step\n",
      "5. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation to retrieve detailed information about each author\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If authors are found in the GB VideosLocation, proceed to the next step\n",
      "4. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\", \"params\": {}, \"output_instructions\": \"Extract uniqueId for each author\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m- chqadeemaktar\n",
      "- abdullaa195\n",
      "- aamira.jr\n",
      "- wallet063\n",
      "- mezanrotiman\n",
      "- skimadrawing\n",
      "- jmblecreateur\n",
      "- glimpse.of.hope\n",
      "- quinneeeee\n",
      "- cb_abdelchafi.1\n",
      "- shahbazshahbaz6602\n",
      "- bonsfreres2024\n",
      "- munarbek_saparaliev\n",
      "- hamid_bouba\n",
      "- halimatououatt\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have retrieved the list of authors and their uniqueIds. Now I need to check if any of them are located in the GB VideosLocation.\n",
      "Action: Loop through the list of uniqueIds and make a GET request to /api/datapoint/author/{id} for each author to check their location.\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/chqadeemaktar\", \"params\": {}, \"output_instructions\": \"Extract region\"}\u001b[0m\n",
      "Observation: Loop through the list of uniqueIds and make a GET request to /api/datapoint/author/{id} for each author to check their location. is not a valid tool, try one of [requests_get, requests_post].\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/chqadeemaktar\", \"params\": {}, \"output_instructions\": \"Extract region\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRegion: N/A (Error_404 - Error_Page)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: The author \"chqadeemaktar\" does not exist or there was an error retrieving their information. I will retry the request for another author.\n",
      "Action: requests_get\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/abdullaa195\", \"params\": {}, \"output_instructions\": \"Extract region\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRegion: N/A (Error: 404 Error - TikStats)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: The author \"abdullaa195\" also does not exist or there was an error retrieving their information. I will retry the request for another author.\n",
      "Action: requests_get\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/aamira.jr\", \"params\": {}, \"output_instructions\": \"Extract region\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRegion: N/A (Error_404 - Error_Page)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: The author \"aamira.jr\" does not exist or there was an error retrieving their information. I will retry the request for another author.\n",
      "Action: requests_get\n",
      "Action Input: {\"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/wallet063\", \"params\": {}, \"output_instructions\": \"Extract region\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRegion: N/A\n",
      "Error: 404 Error - Page not found.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I encountered errors while trying to retrieve information about authors located in the GB VideosLocation. It seems that the authors I attempted to fetch do not exist or there was an issue with the API. To proceed further, I would need to resolve the errors or have additional information to retry the API calls.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI encountered errors while trying to retrieve information about authors located in the GB VideosLocation. It seems that the authors I attempted to fetch do not exist or there was an issue with the API. To proceed further, I would need to resolve the errors or have additional information to retry the API calls.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should inform the user about the issues encountered and ask for more specific details or troubleshoot the problem further.\n",
      "Action: Inform User about the issues encountered\n",
      "Action Input: Notify the user about the errors encountered while trying to retrieve information about authors in the GB VideosLocation and ask for more specific details or permission to troubleshoot further.\u001b[0m\n",
      "Observation: Inform User about the issues encountered is not a valid tool, try one of [api_planner, api_controller].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should revise my approach and try to extract the required information using the available API calls.\n",
      "Action: api_planner\n",
      "Action Input: I need to find the right API calls to retrieve detailed information about authors in the GB VideosLocation.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If no authors are found in the GB VideosLocation, inform the user that the information is not available\n",
      "4. If authors in the GB VideosLocation are found, proceed to the next step\n",
      "5. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation to retrieve detailed information about each author\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan ready, now I need to execute it.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /api/datapoint/authors to retrieve a list of authors\n",
      "2. Evaluate the response to see if any authors are located in the GB VideosLocation\n",
      "3. If authors are found in the GB VideosLocation, proceed to the next step\n",
      "4. GET /api/datapoint/author/{id} for each author located in the GB VideosLocation\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/authors\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract authorId for each author\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor IDs:\n",
      "- 6599233308336324614\n",
      "- 6876607005085254661\n",
      "- 6764324540425896965\n",
      "- 6813660165926945797\n",
      "- 6714969867437081605\n",
      "- 6795561740379915269\n",
      "- 7121308396180390939\n",
      "- 7171835062577054722\n",
      "- 6838509934792754182\n",
      "- 7162904337139794950\n",
      "- 6806765396718699526\n",
      "- 6758942227768116230\n",
      "- 7112329073267540997\n",
      "- 6935580946796676102\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/6599233308336324614\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract author information\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAuthor information not found in the API response.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I was unable to retrieve the author information for the author with ID 6599233308336324614. I would need to retry the API call or check for any potential issues with the request.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI was unable to retrieve the author information for the author with ID 6599233308336324614. I would need to retry the API call or check for any potential issues with the request.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should retry the API call for the author with ID 6599233308336324614 to ensure I have all the necessary information.\n",
      "Action: api_controller\n",
      "Action Input: GET /api/datapoint/author/6599233308336324614\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: \n",
      "{\n",
      "    \"url\": \"https://flaidata.tiktok-alltrends.com:442/api/datapoint/author/6599233308336324614\",\n",
      "    \"params\": {},\n",
      "    \"output_instructions\": \"Extract authorId, nickname, and followers\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mError: 404 Error - TikStats | \n",
      "Summary: The requested page could not be found.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: I cannot complete the plan as the requested page could not be found.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI cannot complete the plan as the requested page could not be found.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should inform the user that I was unable to retrieve the information for the author with ID 6599233308336324614 and ask for further instructions or details.\n",
      "Final Answer: I was unable to retrieve the information about authors using only GB VideosLocation. Please provide more specific details or instructions to assist you further.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'give me info about my authors use only GB VideosLocation',\n",
       " 'output': 'I was unable to retrieve the information about authors using only GB VideosLocation. Please provide more specific details or instructions to assist you further.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_gpt4(\"give me info about my authors use only GB VideosLocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7b9e4-acdd-4c0e-8cb7-ccc4bb2ff13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e959da89-971e-4613-8301-2383636e116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_end = open_api.paths['/api/datapoint/videos']\n",
    "# print(videos_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf4172-f75e-4ae6-aea0-31cf57da828f",
   "metadata": {},
   "source": [
    "# Gorilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f74fe5-b38b-4473-9f05-7b0ebf53a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56921cb4-b2db-4015-9527-5bc393110817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnemonic/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! messages is not default parameter.\n",
      "                messages was transferred to model_kwargs.\n",
      "                Please confirm that messages is what you intended.\n",
      "  warnings.warn(\n",
      "/home/mnemonic/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! functions is not default parameter.\n",
      "                functions was transferred to model_kwargs.\n",
      "                Please confirm that functions is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "completion = ChatOpenAI(\n",
    "            model=\"gorilla-openfunctions-v2\",\n",
    "            temperature=0.0,\n",
    "            #messages=[{\"role\": \"user\", \"content\": \"What's the weather like in the two cities of Boston and San Francisco?\"}],\n",
    "            functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62d0d2bf-e9c0-410c-96b9-0434e6818f86",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#from langchain.prompts.chat import  ChatPromptTemplate\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the weather like in the two cities of Boston and San Francisco?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/arhiv/projects/flaidata/env/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "#from langchain.prompts.chat import  ChatPromptTemplate\n",
    "#chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chain = LLMChain(llm=completion, prompt =\"What's the weather like in the two cities of Boston and San Francisco?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "157bdd41-e140-4a12-a2a2-b4dfc73d9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_gorilla_response(prompt=\"\", model=\"gorilla-openfunctions-v2\", functions=[]):\n",
    "    openai.api_key = \"EMPTY\"  # Hosted for free with â¤ï¸ from UC Berkeley\n",
    "    openai.api_base = \"http://luigi.millennium.berkeley.edu:8000/v1\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gorilla-openfunctions-v2\",\n",
    "            temperature=0.0,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            functions=functions)\n",
    "        # completion.choices[0].message.content, string format of the function call \n",
    "        # completion.choices[0].message.functionsl, Json format of the function call\n",
    "    except:\n",
    "        print('wtf')\n",
    "    return completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d07f4042-efd7-4768-80e1-c5c78b49ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's the weather like in the two cities of Boston and San Francisco?\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a1655ae-f063-4032-bc1a-9c5a6057e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'completion' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_gorilla_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m, in \u001b[0;36mget_gorilla_response\u001b[0;34m(prompt, model, functions)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompletion\u001b[49m\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'completion' referenced before assignment"
     ]
    }
   ],
   "source": [
    "get_gorilla_response(prompt=query, functions=[functions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e96d6d98-5dd2-42d6-ae98-66c0ad2763fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.3'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8741e97b-1bc3-4b73-a16c-e49da5ed5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "def get_prompt(user_query: str, functions: list = []) -> str:\n",
    "    \"\"\"\n",
    "    Generates a conversation prompt based on the user's query and a list of functions.\n",
    "\n",
    "    Parameters:\n",
    "    - user_query (str): The user's query.\n",
    "    - functions (list): A list of functions to include in the prompt.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted conversation prompt.\n",
    "    \"\"\"\n",
    "    if len(functions) == 0:\n",
    "        return f\"USER: <<question>> {user_query}\\nASSISTANT: \"\n",
    "    functions_string = json.dumps(functions)\n",
    "    return f\"USER: <<question>> {user_query} <<function>> {functions_string}\\nASSISTANT: \"\n",
    "\n",
    "# Device setup\n",
    "device : str = \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Model and tokenizer setup\n",
    "model_id : str = \"gorilla-llm/gorilla-openfunctions-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fdba1-d51d-453e-bf83-554b95aae431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83515793-80cf-451f-bce9-1af60a3d6e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49954b24-6366-4129-b560-2f277b6cfeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'USER: <<question>> Call me an Uber ride type \"Plus\" in Berkeley at zipcode 94704 in 10 minutes <<function>> [{\"name\": \"Uber Carpool\", \"api_name\": \"uber.ride\", \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters\", \"parameters\": [{\"name\": \"loc\", \"description\": \"Location of the starting place of the Uber ride\"}, {\"name\": \"type\", \"enum\": [\"plus\", \"comfort\", \"black\"], \"description\": \"Types of Uber ride user is ordering\"}, {\"name\": \"time\", \"description\": \"The amount of time in minutes the customer is willing to wait\"}]}]\\nASSISTANT: uber.ride(loc=\"94704\", type=\"plus\", time=10)'}]\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Pipeline setup\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    batch_size=16,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "query: str = \"Call me an Uber ride type \\\"Plus\\\" in Berkeley at zipcode 94704 in 10 minutes\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"Uber Carpool\",\n",
    "        \"api_name\": \"uber.ride\",\n",
    "        \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters\",\n",
    "        \"parameters\":  [\n",
    "            {\"name\": \"loc\", \"description\": \"Location of the starting place of the Uber ride\"},\n",
    "            {\"name\": \"type\", \"enum\": [\"plus\", \"comfort\", \"black\"], \"description\": \"Types of Uber ride user is ordering\"},\n",
    "            {\"name\": \"time\", \"description\": \"The amount of time in minutes the customer is willing to wait\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate prompt and obtain model output\n",
    "prompt = get_prompt(query, functions=functions)\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8572f-109a-4672-a9ed-4007f93baf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10514d4d-6c00-4718-aeff-93e65acd7091",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model path does not exist: gorilla-openfunctions-v1.Q4_K_M.gguf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall me an Uber ride type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPlus\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m in Berkeley at zipcode 94704 in 10 minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m functions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     {\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUber Carpool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLlama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgorilla-openfunctions-v1.Q4_K_M.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mUSER: <<question>> \u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\u001b[38;5;124m <<function>> \u001b[39m\u001b[38;5;132;01m{functions_string}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mASSISTANT:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm(template\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, query)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{functions_string}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(functions))))\n",
      "File \u001b[0;32m~/arhiv/projects/flaidata/env/lib/python3.10/site-packages/llama_cpp/llama.py:309\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[0;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_threads, n_threads_batch, rope_scaling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, logits_all, embedding, offload_kqv, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_path \u001b[38;5;241m=\u001b[39m lora_path\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m _LlamaModel(\n\u001b[1;32m    312\u001b[0m     path_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_params, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    313\u001b[0m )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Override tokenizer\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Model path does not exist: gorilla-openfunctions-v1.Q4_K_M.gguf"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "query = \"Call me an Uber ride type \\\"Plus\\\" in Berkeley at zipcode 94704 in 10 minutes\"\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"Uber Carpool\",\n",
    "        \"api_name\": \"uber.ride\",\n",
    "        \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters\",\n",
    "        \"parameters\":  [{\"name\": \"loc\", \"description\": \"location of the starting place of the uber ride\"}, {\"name\":\"type\", \"enum\": [\"plus\", \"comfort\", \"black\"], \"description\": \"types of uber ride user is ordering\"}, {\"name\": \"time\", \"description\": \"the amount of time in minutes the customer is willing to wait\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "llm = Llama(model_path=\"gorilla-openfunctions-v1.Q4_K_M.gguf\")\n",
    "template = \"\"\"\n",
    "USER: <<question>> {prompt} <<function>> {functions_string}\\nASSISTANT:\"\"\"\n",
    "print(llm(template.replace('{prompt}', query).replace('{functions_string}', str(functions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb9d7e-3ca9-47c8-8573-b3af0e7b9130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628c5733-e9bb-49c4-82d3-4ae002ec4d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f083560-b7ee-4152-bc43-548bfc2c5cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mUSER: <<question>> \u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\u001b[38;5;124m <<function>> \u001b[39m\u001b[38;5;132;01m{functions_string}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mASSISTANT:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm(template\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{prompt}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[43mquery\u001b[49m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{functions_string}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(functions))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": [
    "# template = \"\"\"\n",
    "# USER: <<question>> {prompt} <<function>> {functions_string}\\nASSISTANT:\"\"\"\n",
    "# print(llm(template.replace('{prompt}', query).replace('{functions_string}', str(functions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d757996a-0b61-431a-9164-61788270d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_gorilla = planner.create_openapi_agent(spec_3, requests_wrapper, llm, verbose=True, return_intermediate_steps=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4a33e13-2237-4203-878d-f4bf1dba3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_gorilla(\"Give me info about my sounds\")\n",
    "# .replace('eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJEYXRhUG9pbnRTZWNyZXQiOiI0NWUxY2UyNy05Y2UzLTQ0ZjQtYTAzNC0wM2MzZGE1M2VlZTMiLCJuYmYiOjE3MDc3MzAxNjAsImV4cCI6MTcxMDIzNTc2MCwiaWF0IjoxNzA3NzMwMTYwLCJpc3MiOiJTZXJ2ZXIiLCJhdWQiOiJDbGllbnQifQ.-LS9fpGKWsXzIzMTrcIUEq67t3mEy3auVL5-GbkN20s', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790d262-1917-40c9-8e1d-fb8bf791312a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4856fb92-a69f-4898-89c8-0c2b31ac074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('spec.pickle', 'wb') as handle:\n",
    "#     pickle.dump(c_spec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('spec.pickle', 'rb') as handle:\n",
    "    c_spec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d9736917-9e4e-46e8-a3fe-1f491c45daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_functions = [] \n",
    "new_descriptions = {\n",
    "\"/api/datapoint/sounds\":\"Get sounds or musics for customer given the sorting, take, soundType, Days, VideosLocation, Category, isArtist as parameters if it in customer request\",\n",
    "\"/api/datapoint/authors\":\"Get authors or influencers for customer given the take, Verified, SubscribersTo, SubscribersFrom, LikesTo, LikesFrom, ClipsTo, ClipsFrom, SubscribedTo, SubscribedFrom, VideosLocation, ArtistLocation, Sorting, Order, Search, Days as parameters if it in customer request\",\n",
    "\"/api/datapoint/author\":\"Get information about single author or analyze account for customer given the authorId, period as parameters if it in customer request\"    \n",
    "}\n",
    "\n",
    "for path, desc in c_spec[\"paths\"].items():\n",
    "    new_param = list(desc['get']['parameters'])\n",
    "    new_param.pop(0)\n",
    "    new_functions.append(\n",
    "        {\"name\": path.split('/')[-1],\n",
    "         \"api_name\": path,\n",
    "         \"description\": new_descriptions[path],\n",
    "         \"parameters\": new_param}\n",
    "    )\n",
    "\n",
    "new_spec = c_spec.copy()\n",
    "for path, desc in c_spec[\"paths\"].items():\n",
    "    new_param = list(desc['get']['parameters'])\n",
    "    new_param.pop(0)\n",
    "    new_spec[\"paths\"][path]['get']['parameters'] = new_param\n",
    "    new_spec[\"paths\"][path]['get']['description'] = new_descriptions[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f417019-2831-4682-9439-21d98b8f9aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be3cf11b-21e1-479c-b280-610b00ceabb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "637d7408-e2c2-4f31-a70b-2ca04a63a049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6566efb6-ce07-4225-a5a2-a1ba87ca7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_properties = {\n",
    "\"/api/datapoint/sounds\": new_spec[\"paths\"]['/api/datapoint/sounds']['get']['responses']['200']['content']['application/json']['examples']['default']['value']['data']['stats'][0]['music'],\n",
    "\"/api/datapoint/authors\":new_spec[\"paths\"]['/api/datapoint/authors']['get']['responses']['200']['content']['application/json']['examples']['default']['value']['data']['stats'][0],\n",
    "}\n",
    "\n",
    "for path, source in new_properties.items():\n",
    "    res = {}\n",
    "    for k,v in source.items():    \n",
    "        if isinstance(v, str):\n",
    "            res[k] = {\"type\": \"string\"}\n",
    "        elif isinstance(v, int):\n",
    "            res[k] = {\"type\": \"integer\"}\n",
    "        elif isinstance(v, bool):\n",
    "            res[k] = {\"type\": \"boolean\"}\n",
    "        else:\n",
    "            print('Not supported type: ', type(v))\n",
    "    new_spec[\"paths\"][path]['get']['responses']['200']['content']['application/json']['schema']['properties'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d7607a64-dd82-4db6-ab16-4ee0893cf68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get authors or influencers for customer given the take, Verified, SubscribersTo, SubscribersFrom, LikesTo, LikesFrom, ClipsTo, ClipsFrom, SubscribedTo, SubscribedFrom, VideosLocation, ArtistLocation, Sorting, Order, Search, Days as parameters if it in customer request'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_spec[\"paths\"]['/api/datapoint/authors']['get']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c381209f-b207-49d2-a8a6-c2ac1d8c90bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authorId': {'type': 'string'},\n",
       " 'subscribers': {'type': 'integer'},\n",
       " 'subscribedAt': {'type': 'integer'},\n",
       " 'clips': {'type': 'integer'},\n",
       " 'likes': {'type': 'integer'},\n",
       " 'diggCount': {'type': 'integer'},\n",
       " 'uniqueId': {'type': 'string'},\n",
       " 'nickname': {'type': 'string'},\n",
       " 'signature': {'type': 'string'},\n",
       " 'verified': {'type': 'integer'},\n",
       " 'parseDate': {'type': 'string'},\n",
       " 'updateDate': {'type': 'string'},\n",
       " 'region': {'type': 'string'}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_spec[\"paths\"]['/api/datapoint/authors']['get']['responses']['200']['content']['application/json']['schema']['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7940cd1-18e4-47c2-8649-e08a6dc6f686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d7edd57-c929-48ce-8854-97e11f935b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"flai_spec.json\", \"w\") as file:\n",
    "    # Convert the dictionary to JSON and write it to the file\n",
    "    json.dump(new_spec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d1c372ab-3f10-4c57-b4eb-795f081fcd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mnemonic/arhiv/projects/flaidata\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7372d6-8938-4152-98d4-2c903fb4e823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff88ae1d-e2e9-4197-b7c2-b90772a155ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_spec[\"paths\"]['/api/datapoint/sounds']['get']['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d22df3c4-1f0e-4782-a413-dfc3cd7c2a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnemonic/arhiv/projects/flaidata/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 1 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19508.39it/s]\n",
      "Fetching 1 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 182.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "from accelerate import Accelerator\n",
    "\n",
    "config = {'max_new_tokens': 512, \n",
    "          'repetition_penalty': 1.1, \n",
    "          'context_length': 4000, \n",
    "          'temperature':0.1, \n",
    "          'gpu_layers':50\n",
    "         }\n",
    "\n",
    "llm = CTransformers(\n",
    "        model=\"TheBloke/gorilla-openfunctions-v1-GGUF\", \n",
    "        model_file=\"gorilla-openfunctions-v1.Q4_K_M.gguf\", \n",
    "        model_type=\"llama\",\n",
    "        gpu_layers=50, \n",
    "        config=config,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "accelerator = Accelerator()\n",
    "llm, config = accelerator.prepare(llm, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "054cf37e-8bbb-4e7d-b31f-9de7256f75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(c_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b482cc3-3941-43f8-8980-78f464ea590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_prompt = \"You should return only functions from <<function>> block. You should find similar meaning words from customer query and match it with parameters from <<function>> block for current function. Return only parameters that in parameters from <<function>> block for current function and customer query in the same time. If it additional parameters not gives, use default values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba576e8e-baca-4a57-a3cb-4cd2235757e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "USER: <<question>> {prompt} <<function>> {functions_string}\\nASSISTANT:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55773067-a3a9-4d91-90da-0f7262ea2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnemonic/arhiv/projects/flaidata/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /api/datapoint/sounds(take=20, sorting=\"new\", name=\"sounds\")\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me info about my sounds return 20 items from last 50 days and sorting by new compositions\"\n",
    "print(llm(template.replace('{prompt}', query).replace('{functions_string}', str(new_functions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cdc0d-9b8d-4c64-b31a-e4f00810c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c6d8275-fe1c-4687-acb5-ee7985a71ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /api/datapoint/authors(take=50, Verified=\"verified\", SubscribersTo=666)\n"
     ]
    }
   ],
   "source": [
    "query = \"Could you present my best 50 verified influencers with have most than 666 subscribers?\"\n",
    "print(llm(template.replace('{prompt}', query).replace('{functions_string}', str(new_functions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0897114-cf45-4ac5-af9e-5aaee7a4f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /api/datapoint/accounts/97614653324771328\n"
     ]
    }
   ],
   "source": [
    "query = \"Find info about account 97614653324771328\"\n",
    "print(llm(template.replace('{prompt}', query).replace('{functions_string}', str(new_functions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8ac53-1323-4738-9a3e-c87e2142902b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
